{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wafer Classification using Amazon Lookout for Vision - Sample Jupyter Notebook\n",
    "\n",
    "The image is taken from https://upload.wikimedia.org/wikipedia/commons/e/e2/Silicon_wafer.jpg. For the sample picture (good/bad folder) we modified the images.\n",
    "\n",
    "### Environmental variables\n",
    "\n",
    "In a very first step we want to define the two global variables needed for this notebook:\n",
    "\n",
    "- bucket: the S3 bucket that you will create and then use as your source for Amazon Lookout for Vision\n",
    "    - Note: Please read the comments carefully. Depending on your region you need to uncomment the correct command\n",
    "- project: the project name you want to use in Amazon Lookout for Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "bucket = \"MY_BUCKET_NAME\"\n",
    "project = \"MY_PROJECT_NAME\"\n",
    "os.environ[\"BUCKET\"] = bucket\n",
    "os.environ[\"PROJECT\"] = project\n",
    "os.environ[\"REGION\"] = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your region here with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your region:\n",
    "print(boto3.session.Session().region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your region follow the instructions of the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create your S3 bucket:\n",
    "## if your region is eu-east-1 please execute:\n",
    "\n",
    "# !aws s3api create-bucket --bucket $BUCKET\n",
    "\n",
    "## in all other cases use:\n",
    "\n",
    "# !aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the newest version of AWS CLI\n",
    "\n",
    "At the time of creation Amazon SageMaker notebooks still had an older version of CLI installed. Hence, you couldn't use the newest services, e.g. Amazon Lookout for Vision. As it never hurts to run on the newest version the upcoming cells can remain.\n",
    "\n",
    "Note: Code is taken from https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html. Here you also find more information on updating CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CLI v2\n",
    "!curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip here\n",
    "!unzip awscliv2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run update\n",
    "!sudo ./aws/install --update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check version\n",
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove downloaded/extracted files from local instance\n",
    "!rm -rf aws\n",
    "!rm awscliv2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders that will be necessary for Amazon Lookout for Vision\n",
    "\n",
    "In Amazon Lookout for Vision - see also\n",
    "- https://aws.amazon.com/lookout-for-vision/ and\n",
    "- https://aws.amazon.com/blogs/aws/amazon-lookout-for-vision-new-machine-learning-service-that-simplifies-defect-detection-for-manufacturing/\n",
    "if you already have pre-labeled images available, as it is the case in this example, you can already establish a folder structure that lets you define training and validation. Further, images are labeled for Amazon Lookout via the corresponding folder (normal=good, anomaly=bad). We will create this structure locally and then upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir training\n",
    "!mkdir training/anomaly\n",
    "!mkdir training/normal\n",
    "!mkdir validation\n",
    "!mkdir validation/anomaly\n",
    "!mkdir validation/normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preparation and EDA\n",
    "\n",
    "Next, we want to explore the images available for you a little. Then, in order to create many more images for our model training, we will rotate the images slightly and generate more of them. At the end we aim to have 90% good and 10% bad images. Which is a likely case - at least in the Yield Enhancement department of a semiconductor company.\n",
    "\n",
    "### Load libraries and check out main image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings for skimage to avoid frustration in this little test case :)\n",
    "import skimage\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image (wafer.jpg)\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import rotate\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "filename = 'good/wafer.jpg'\n",
    "wafer = io.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matplotlib to display the image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "io.imshow(wafer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On top: load all available images (good & bad) and display them row-wise:\n",
    "# Top row: good images\n",
    "# Bottom row: bad images\n",
    "\n",
    "# Define plot figure\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "columns = 5\n",
    "rows = 2\n",
    "\n",
    "# For all images in good/ and bad/ folder...\n",
    "i = 1\n",
    "path = [\"good/\", \"bad/\"]\n",
    "for p in path:\n",
    "    files = os.listdir(path=p)\n",
    "    # ...load all files and do...\n",
    "    for file in files:\n",
    "        # ...check if they are not relevant,...\n",
    "        if \".ipynb_checkpoints\" in file:\n",
    "            continue\n",
    "        # ...if they are load them and add them to the plot figure\n",
    "        img = io.imread(\"{}/{}\".format(p, file))\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "        i += 1\n",
    "# Finally show the image:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate MORE images\n",
    "\n",
    "For the sake of simplicity we will do the following:\n",
    "\n",
    "- Take all good images\n",
    "    - Rotate them 360 times (1 degree at a time)\n",
    "    - Randomly save it either to training/ or validation/ folder (ratio: 80:20)\n",
    "- Take all bad images\n",
    "    - Rotate them 36 times (10 degrees at a time)\n",
    "    - Randomly save it either to training/ or validation/ folder (ratio: 80:20)\n",
    "\n",
    "In a real-world scenario you might want to apply even more transformation (color mapping, etc.). For this example we keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each type of wafer good/ or bad/...\n",
    "path = [\"good/\", \"bad/\"]\n",
    "for p in path:\n",
    "    # ...print the path (to know where the loop is) and\n",
    "    # list all files.\n",
    "    print(p)\n",
    "    files = os.listdir(path=p)\n",
    "    for file in files:\n",
    "        # For each file check it's nonsense or a real image.\n",
    "        if \".ipynb_checkpoints\" in file:\n",
    "            continue\n",
    "        # If it's a real image print it (to know where the loop is) and\n",
    "        # form a filename and load the corresponding wafer image:\n",
    "        print(file)\n",
    "        filename = '{}{}'.format(p, file)\n",
    "        wafer = io.imread(filename)\n",
    "        # steps = 1 if it's a good wafer (\"1 degree at a time\"),\n",
    "        # if it's a bad wafer then make steps = 10 (\"10 degrees at a time\").\n",
    "        # Also note that the subfolder (normal = good / anomaly = bad wafer)\n",
    "        # is set here:\n",
    "        steps = 1\n",
    "        subfolder = \"normal\"\n",
    "        if p == \"bad/\":\n",
    "            steps = 10\n",
    "            subfolder = \"anomaly\"\n",
    "        # Now it's time to rotate each image and save it to the corresponding folder.\n",
    "        # An important concept is to randomly assign each image either the training\n",
    "        # or the validation dataset:\n",
    "        for i in range(0, 360, steps):\n",
    "            # ~80% training data - ~20% validation data:\n",
    "            choice = np.random.choice(a=[0, 1], size=1, replace=True, p=[0.8, 0.2])[0]\n",
    "            # Check the choice and set the main folder:\n",
    "            folder = \"training\"\n",
    "            if choice == 1:\n",
    "                folder = \"validation\"\n",
    "            # Form the file name, rotate the image and save it:\n",
    "            fname = \"{}/{}/{}_{}\".format(folder, subfolder, str(i), file)\n",
    "            rot = rotate(image=wafer, angle=i)\n",
    "            rot = img_as_ubyte(image=rot)\n",
    "            io.imsave(fname=fname, arr=rot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the *manifest* files\n",
    "\n",
    "You might be familiar with the manifest files if you ever used Amazon SageMaker Ground Truth. If you are not don't worry about that section too much.\n",
    "\n",
    "If you are still interested in what's happening, you can continue reading:\n",
    "\n",
    "Each dataset training/ as well as validation/ needs a manifest file. This file is used by Amazon Lookout for Vision to determine where to look for the images. The manifest follows a fixed structure. Most importantly are the keys (it's JSON formatted) *source-ref* this is the location for each file, *auto-label* the value for each label (0=bad, 1=good), *folder* which indicates whether Amazon Lookout is using training or validation and *creation-date* as this let's you know when an image was put in place. All other fields are pre-set for you.\n",
    "\n",
    "Each manifest file itself contains N JSON objects, where N is the number of images that are used in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime for datetime generation and json to dump the JSON object\n",
    "# to the corresponding files:\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Current date and time in manifest file format:\n",
    "now = datetime.now()\n",
    "dttm = now.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "\n",
    "# The two datasets used: training and validation\n",
    "datasets = [\"training\", \"validation\"]\n",
    "\n",
    "# For each dataset...\n",
    "for ds in datasets:\n",
    "    # ...list the folder available (normal or anomaly).\n",
    "    folders = os.listdir(\"./{}\".format(ds))\n",
    "    # Then open the manifest file for this dataset...\n",
    "    with open(\"{}.manifest\".format(ds), \"a\") as f:\n",
    "        for folder in folders:\n",
    "            # ...and iterate through both folders by first listing\n",
    "            # the corresponding files and setting the appropriate label\n",
    "            # (as noted above: 1 = good, 0 = bad):\n",
    "            files = os.listdir(\"./{}/{}\".format(ds, folder))\n",
    "            label = 1\n",
    "            if folder == \"anomaly\":\n",
    "                label = 0\n",
    "            # For each file in the folder...\n",
    "            for file in files:\n",
    "                # ...generate a manifest JSON object and save it to the manifest\n",
    "                # file. Don't forget to add '/n' to generate a new line:\n",
    "                manifest = {\n",
    "                  \"source-ref\": \"s3://{}/{}/{}/{}\".format(bucket, ds, folder, file),\n",
    "                  \"auto-label\": label,\n",
    "                  \"auto-label-metadata\": {\n",
    "                    \"confidence\": 1,\n",
    "                    \"job-name\": \"labeling-job/auto-label\",\n",
    "                    \"class-name\": folder,\n",
    "                    \"human-annotated\": \"yes\",\n",
    "                    \"creation-date\": dttm,\n",
    "                    \"type\": \"groundtruth/image-classification\"\n",
    "                  }\n",
    "                }\n",
    "                f.write(json.dumps(manifest)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload manifest files and images to S3\n",
    "\n",
    "Now it's time to upload all the images and the manifest files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload manifest files:\n",
    "!aws s3 cp training.manifest s3://$BUCKET/training.manifest\n",
    "!aws s3 cp validation.manifest s3://$BUCKET/validation.manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload images:\n",
    "!aws s3 cp training/ s3://$BUCKET/training/ --recursive\n",
    "!aws s3 cp validation/ s3://$BUCKET/validation/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Lookout for Vision\n",
    "\n",
    "We are almost done. You have a couple of options on how to create your Amazon Lookout project (console, CLI or boto3). We chose CLI in this example. We highly recommend to check out the console, too. It's so simple to generate a project and let a model be trained. This is what we should show to our customers, too!\n",
    "\n",
    "The steps we take with CLI are:\n",
    "\n",
    "1. Create a project (the name as been set right at the beginning)\n",
    "2. Tell your project where to find your training dataset. This is done via the manifest file for training.\n",
    "3. Tell your project where to find your validation dataset. This is done via the manifest file for validation.\n",
    "    - Note: This step is optional. In general all 'validation' related code, etc. is optional. Amazon Lookout for Vision will also work with 'training' dataset only. We chose to use both as training and validation is a common (best) practice when training AI/ML models. And we should always let our customer know this to help them get to the next level.\n",
    "4. Create a model. This command will trigger the model training and validation.\n",
    "\n",
    "**Note**: Training a model can (will) take a few hours as it uses Deep Learning in the background. Once your model is trained (you can for instance check progress in the console) you can continue with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lookoutvision create-project --project-name $PROJECT\n",
    "!aws lookoutvision create-dataset --project-name $PROJECT --dataset-type train --dataset-source 'GroundTruthManifest={S3Object={Bucket=$BUCKET,Key=training.manifest,VersionId=\"1\"}}'\n",
    "!aws lookoutvision create-dataset --project-name $PROJECT --dataset-type test --dataset-source 'GroundTruthManifest={S3Object={Bucket=$BUCKET,Key=validation.manifest,VersionId=\"1\"}}'\n",
    "!aws lookoutvision create-model --project-name $PROJECT --output-config 'S3Location={Bucket=$BUCKET,Prefix=model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment\n",
    "\n",
    "Getting the model in an operating stage is as easy as telling it to \"start\". This process also takes a few minutes. So, please be patient. You can again check in the console (or via CLI) the status of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lookoutvision start-model --project-name $PROJECT --model-version 1 --min-inference-units 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "#### CLI\n",
    "\n",
    "Making predictions via CLI requires the project name, model version, content type and a sample images. We are using a local images from the SageMaker instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lookoutvision detect-anomalies --project-name $PROJECT --model-version 1 --content-type image/jpeg --body ./bad/particle.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boto3\n",
    "\n",
    "You can also use boto3 to achieve the same. An application how this could be used can be found under https://collaborate-corp.amazon.com/nuxeo/ui/#!/doc/976afb34-b53c-4ddc-a8a6-7d316dc0f951.\n",
    "\n",
    "As mentioned earlier the newest boto3 version is not available in all of our services. This is also true for AWS Lambda. That's why the above artifact uses Lambda Layers to enable the below boto3 call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"lookoutvision\")\n",
    "\n",
    "image = open(\"/home/ec2-user/SageMaker/jupyter-notebook/bad/particle.jpg\", \"rb\")\n",
    "\n",
    "response = client.detect_anomalies(\n",
    "    ProjectName=project,\n",
    "    ModelVersion='1',\n",
    "    Body=image,\n",
    "    ContentType='image/jpeg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"DetectAnomalyResult\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE FRUGAL\n",
    "\n",
    "If you don't need your model anymore please stop it to save costs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws lookoutvision stop-model --project-name $PROJECT --model-version 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
